{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情報システム工学演習 画像処理 OpenCVチュートリアル\n",
    "\n",
    "OpenCVを使った画像処理の演習です。まずはこのチュートリアルで基礎の基礎を学んでいきましょう。\n",
    "ちなみに、OpenCVの公式チュートリアルが https://docs.opencv.org/4.x/d9/df8/tutorial_root.html にあるので、こちらも活用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "インストールについては```README.md```を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np  # PythonのOpenCVでは、画像はnumpyのarrayとして管理される\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "# 画像表示用の関数（jupyter notebookでインラインで表示したい時向け）\n",
    "def imshow_inline(img):\n",
    "  if img.ndim == 3:\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # OpenCVの画像は、BGRの順に色が並んでいるので\n",
    "    display(Image.fromarray(img))\n",
    "  else:\n",
    "    display(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の読み込み・書き込み編"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 画像ファイルの読み込み・書き込み\n",
    "img = cv2.imread(\"sample/sample.jpg\")\n",
    "# img = cv2.imread(\"sample/sample.jpg\",cv2.IMREAD_GRAYSCALE)  # 強制的にグレースケール（白黒画像）として読み込む場合\n",
    "\n",
    "# てきとうな処理（リサイズしてみた）\n",
    "#dst = cv2.resize(img,dsize=None,fx=0.5,fy=0.5)  # 縦横半分\n",
    "dst = cv2.resize(img,dsize=(512,256))  # 指定したサイズ\n",
    "\n",
    "# 画像の書き込み\n",
    "cv2.imwrite(\"out.png\",dst)\n",
    "\n",
    "# インライン表示する場合\n",
    "#imshow_inline(img)\n",
    "#imshow_inline(dst)\n",
    "\n",
    "# 新しいウインドウを開いて表示する場合（ウインドウを閉じるか、なにかキーを押すと終了）\n",
    "cv2.namedWindow('src') # 指定されたタイトルのウインドウを開く\n",
    "cv2.imshow('src',img)  # 指定されたタイトルのウインドウに画像を表示\n",
    "cv2.namedWindow('dst') # 指定されたタイトルのウインドウを開く\n",
    "cv2.imshow('dst',dst)  # 指定されたタイトルのウインドウに画像を表示\n",
    "cv2.waitKey(0)           # キーが押されるまで{引数}[ms]の間待つ（0の場合はずっと待つ）\n",
    "cv2.destroyAllWindows()  # ウインドウを閉じる。!!!jupyter上の場合、これを忘れるとフリーズする!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 動画の読み込み\n",
    "cap = cv2.VideoCapture('sample/sample.avi')\n",
    "\n",
    "end_flag, frame = cap.read()  # 最初のフレームを読み込み\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "cv2.namedWindow('image') # 'image'というタイトルのウインドウを開く\n",
    "\n",
    "while end_flag == True:\n",
    "  cv2.imshow('image',frame)  # 'image'というタイトルのウインドウに画像を表示\n",
    "\n",
    "  key = cv2.waitKey(30) # キーが押されるまで{引数}[ms]の間待つ（0の場合はずっと待つ）\n",
    "  if key == 27 or key == ord('q'):  # qかESCが押されたら途中で終了\n",
    "    break\n",
    "\n",
    "  end_flag, frame = cap.read() # 次のフレームを読み込み\n",
    "\n",
    "cv2.destroyAllWindows()  # ウインドウを閉じる\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# webカメラの読み込み\n",
    "# !!!注意!!! 当然ですが、カメラがつながっていないとエラーになります\n",
    "\n",
    "# 引数はデバイスの順番。複数のカメラがつながっている場合は1などに変えると変わる\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "end_flag, frame = cap.read()  # 最初のフレームを読み込み\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "cv2.namedWindow('image') # 'image'というタイトルのウインドウを開く\n",
    "\n",
    "while end_flag == True:\n",
    "  cv2.imshow('image',frame)  # 'image'というタイトルのウインドウに画像を表示\n",
    "\n",
    "  key = cv2.waitKey(30) # キーが押されるまで{引数}[ms]の間待つ（0の場合はずっと待つ）\n",
    "  if key == 27 or key == ord('q'):  # qかESCが押されたら途中で終了\n",
    "    break\n",
    "\n",
    "  end_flag, frame = cap.read() # 次のフレームを読み込み\n",
    "\n",
    "cv2.destroyAllWindows()  # ウインドウを閉じる\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画素へのアクセスと色の操作編\n",
    "\n",
    "Tips:\n",
    "- 画像は配列。画像のサイズを縦h, 横w, チャンネル数cで表すと、\n",
    "  - グレースケール（1ch）画像の場合、(h,w)の2次元のnumpy配列\n",
    "  - カラー画像（3ch, BGRの順で色が並ぶ）の場合、(h,w,c)の3次元のnumpy配列\n",
    "    - カラー画像の画素のチャンネルは、それぞれ青・緑・赤の色の強さを表す。\n",
    "- 原点は左上。縦軸をy、横軸をxとすると、左からx、上からy画素目の画素へのアクセスは`img[y][x] (img[y,x]でもOK)`（1ch画像の場合）\n",
    "- 配列の各要素には0~255の8bit (uint8)が格納されており、大きい値が明るい（あるいは色が強い）画素を表す。\n",
    "- 画素へのアクセスや操作は、for文の2重ループ（それぞれ縦横の座標を表す）で走査する方法がある\n",
    "  - Pythonのfor文は遅いので、numpyやOpenCVの関数を使った効率化を積極的に検討すること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# グレースケール画像の操作\n",
    "img_color = cv2.imread(\"sample/sample.jpg\")\n",
    "print(\"color (BGR): \",img_color.shape, \", type: \", img_color.dtype)\n",
    "\n",
    "img_gray = cv2.cvtColor(img_color,cv2.COLOR_BGR2GRAY) # グレイスケールに変換\n",
    "print(\"grayscale: \",img_gray.shape, \", type: \", img_color.dtype)\n",
    "\n",
    "# 各画素をスキャンして、条件にあった画素だけ書き換える（効率悪い。おそい。）\n",
    "out1 = img_gray.copy()\n",
    "out2 = img_gray.copy()\n",
    "for y in range(img_gray.shape[0]):\n",
    "  for x in range(img_gray.shape[1]):\n",
    "\n",
    "    # 例1: 画素値が128よりも小さい場合に全部255（白）にする\n",
    "    if out1[y,x] < 128:\n",
    "      out1[y,x] = 255\n",
    "\n",
    "    # 例2: y座標が30以上110未満の部分を黒塗り\n",
    "    if 30 <= y < 110:\n",
    "      out2[y,x] = 0\n",
    "\n",
    "# 例1は、numpyを使って以下のようにも実現できる。はやい。\n",
    "out_numpy = np.where(img_gray<128, 255, img_gray)\n",
    "# 例2は、numpyの配列操作で以下のように書ける。はやい。\n",
    "out2_numpy = img_gray.copy()\n",
    "out2_numpy[30:110,:] = 0\n",
    "\n",
    "imshow_inline(img_gray)\n",
    "imshow_inline(out1)\n",
    "imshow_inline(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# カラー画像の操作\n",
    "img = cv2.imread(\"sample/sample.jpg\")\n",
    "\n",
    "out = img.copy()\n",
    "for y in range(img.shape[0]):\n",
    "  for x in range(img.shape[1]):\n",
    "\n",
    "    # R（赤成分）だけ大きい場合、黒(0,0,0)にする\n",
    "    if img[y,x,0] < 128 and img[y,x,1] < 128 and img[y,x,2] > 128:\n",
    "      out[y,x,0] = 0\n",
    "      out[y,x,1] = 0\n",
    "      out[y,x,2] = 0\n",
    "\n",
    "# OpenCVとnumpyを使って以下のようにも書ける\n",
    "out_numpy = img.copy()\n",
    "mask = cv2.inRange(img, np.array([0,0,128]), np.array([128,128,255]))\n",
    "mask = 255-mask # Rだけ大きい画素「以外」を残したいので\n",
    "mask = np.dstack((mask,mask,mask))  # 3chにしたいので\n",
    "out_numpy = cv2.bitwise_and(img, mask)\n",
    "#out_numpy = img * (mask/255).astype(np.uint8)\n",
    "\n",
    "imshow_inline(img)\n",
    "imshow_inline(out)\n",
    "imshow_inline(out_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の統計量\n",
    "\n",
    "画像のヒストグラム（度数分布）を計算するなどが代表的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"sample/sample.jpg\")\n",
    "\n",
    "hist_B = cv2.calcHist([img],channels=[0],mask=None,histSize=[256],ranges=[0,256])  # B:0, G:1, R:2\n",
    "hist_G = cv2.calcHist([img],channels=[1],mask=None,histSize=[256],ranges=[0,256])  # B:0, G:1, R:2\n",
    "hist_R = cv2.calcHist([img],channels=[2],mask=None,histSize=[256],ranges=[0,256])  # B:0, G:1, R:2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(0,256)\n",
    "x_axis = np.array(x)\n",
    "ax.plot(x_axis, np.array(hist_B), label='B', color='blue')\n",
    "ax.plot(x_axis, np.array(hist_G), label='G', color='green')\n",
    "ax.plot(x_axis, np.array(hist_R), label='R', color='red')\n",
    "ax.legend(loc=0)    # 凡例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のフィルタリング\n",
    "\n",
    "画像の編集や特徴の抽出に使える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 画像を「ぼかす」\n",
    "\n",
    "img = cv2.imread(\"sample/wani.png\")\n",
    "dst = cv2.GaussianBlur(img,ksize=(21,21),sigmaX=7)\n",
    "\n",
    "print(\"input\")\n",
    "imshow_inline(img)\n",
    "\n",
    "print(\"blurred\")\n",
    "imshow_inline(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 画像から「エッジ」を抽出する\n",
    "\n",
    "img = cv2.imread(\"sample/prims.png\")\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # グレイスケールに変換\n",
    "\n",
    "grad_x = cv2.Sobel(img_gray,cv2.CV_64F,1,0,ksize=5) # x方向の変化の大きな点（縦方向のエッジ）を検出\n",
    "grad_y = cv2.Sobel(img_gray,cv2.CV_64F,0,1,ksize=5) # y方向の変化の大きな点（横方向のエッジ）を検出\n",
    "\n",
    "# 勾配（画素値の変化）の強さと方向を計算する。angle: [0,360)\n",
    "magnitude, angle = cv2.cartToPolar(grad_x, grad_y,angleInDegrees=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(magnitude)\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(angle)\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の変形編\n",
    "\n",
    "座標(x,y)を操作することで、画像を変形（ワーピング）することができる。詳しくは、射影変換（ホモグラフィ変換）を調べてみよう\n",
    "\n",
    "以下は、2つの画像を張り合わせる例。4組の対応点を指定し、その前後の変換（ホモグラフィ行列）を計算して変形する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imgをrefに張り合わせることを考える\n",
    "ref = cv2.imread(\"sample/pano_ref.jpg\") # ベースとなる画像（BGR）\n",
    "src = cv2.imread(\"sample/pano_src.jpg\") # 変換する画像（BGR）\n",
    "\n",
    "print(\"ref\")\n",
    "imshow_inline(ref)\n",
    "print(\"src\")\n",
    "imshow_inline(src)\n",
    "\n",
    "pts_ref = np.float32([[923,156],[1281,143],[1276,760],[916,745]]) # refの点(x', y')\n",
    "pts_src = np.float32([[88,163],[438,190],[437,760],[78,782]])  # srcの点(x, y)\n",
    "\n",
    "# 横幅2倍の画像を作って、そこに貼り付けることにした。配列作成時のshapeの設定はw,h,cの順なので注意\n",
    "dst = np.zeros((src.shape[0],src.shape[1]*2,3))\n",
    "dst[:,0:ref.shape[1],:] = ref # 左半分にrefをコピー\n",
    "H = cv2.getPerspectiveTransform(pts_src,pts_ref)  # 最小二乗法によるホモグラフィ行列の推定（img -> refへの変換）\n",
    "src_warped = cv2.warpPerspective(src, H, (src.shape[1]*2,src.shape[0]), flags=cv2.INTER_NEAREST) # ホモグラフィ行列を使ったワーピング\n",
    "\n",
    "mask = np.where(src_warped==0,0,1).astype(np.uint8) # 変換後srcの値がある場所が1になるマスク画像を作る\n",
    "dst = dst*(1-mask) + src_warped*mask  # アルファブレンディング\n",
    "dst = dst.astype(np.uint8)  # uint8に変換\n",
    "\n",
    "print(\"dst\")\n",
    "imshow_inline(dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の対応付け\n",
    "\n",
    "画像の同じ部分はどこか？を探したい。そんな時は対応付けが便利。\n",
    "画像上の特徴的な点を探し、それら同士のマッチングを行っている。\n",
    "\n",
    "https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imgとref間のマッチングをする\n",
    "ref = cv2.imread(\"sample/pano_ref.jpg\")\n",
    "src = cv2.imread(\"sample/pano_src.jpg\")\n",
    "\n",
    "# ここでは、ORBという特徴点・特徴量を使ってみる。\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# 各画像に対する特徴点（keypoint）とそれに付随する特徴量（descriptor）の計算\n",
    "kp_ref, des_ref = orb.detectAndCompute(ref, None)\n",
    "kp_src, des_src = orb.detectAndCompute(src, None)\n",
    "\n",
    "# マッチング。特徴量の性質から、ハミング距離を使う。\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = matcher.match(des_ref,des_src)\n",
    "\n",
    "# 全対応を可視化。対応づいた点同士が線で結ばれる。\n",
    "corr_disp = cv2.drawMatches(ref,kp_ref,src,kp_src,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "imshow_inline(corr_disp) # 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ユーザ入力の取得・描画\n",
    "OpenCVでは、namedWindow上でのマウスやキーボード入力の取得が可能\n",
    "\n",
    "また、画像上への描画関数も実装されている。丸以外に、直線（```cv2.line```）、長方形（```cv2.rectangle```）なども。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"sample/sample.jpg\")\n",
    "draw = img.copy()\n",
    "\n",
    "# マウスコールバック関数。マウスイベントが発生すると呼ばれる\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(draw,(x,y),10,(0,255,0), 2)\n",
    "        print(\"left press: (\", x, \",\", y, \")\")\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        cv2.circle(draw,(x,y),10,(255,0,0), 2)\n",
    "        print(\"right press: (\", x, \",\", y, \")\")\n",
    "\n",
    "cv2.namedWindow(\"window\")\n",
    "cv2.setMouseCallback(\"window\", mouse_callback)  # マウスコールバック関数の設定\n",
    "\n",
    "key = 0\n",
    "while True:\n",
    "  cv2.imshow('window',draw)  # 'image'というタイトルのウインドウに画像を表示\n",
    "\n",
    "  # キーボード入力はcv2.waitKeyで。\n",
    "  key = cv2.waitKey(30) # キーが押されるまで{引数}[ms]の間待つ（0の場合はずっと待つ）\n",
    "  if key == 27 or key == ord('q'):  # qかESCが押されたら途中で終了\n",
    "    break\n",
    "\n",
    "cv2.destroyAllWindows()  # ウインドウを閉じる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 物体検出\n",
    "ここでは、Haar-Cascade特徴を使った顔検出を紹介する。それ以外の学習済み特徴も、`haarcascades`ディレクトリ以下にある。目鼻口なども。\n",
    "\n",
    "https://docs.opencv.org/4.x/db/d28/tutorial_cascade_classifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 学習済みファイルの入力\n",
    "face_cascade_file  = \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_file)\n",
    "\n",
    "img = cv2.imread(\"sample/face.png\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_list = face_cascade.detectMultiScale(img_gray, minSize=(30, 30))   # 顔検出\n",
    "\n",
    "for (x, y, w, h) in face_list:  # 検出した顔\n",
    "    #print(face_list)\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 225), thickness = 3)  # 顔の枠を描く\n",
    "\n",
    "imshow_inline(img) # 表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}